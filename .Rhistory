confusionMatrix(predictRF,testing$diagnosis)
confusionMatrix(predictGBM,testing$diagnosis)
confusionMatrix(predictLDA,testing$diagnosis)
confusionMatrix(combPredict,testing$diagnosis)
confusionMatrix(predictRF,testing$diagnosis)
confusionMatrix(predictGBM,testing$diagnosis)
confusionMatrix(predictLDA,testing$diagnosis)
confusionMatrix(combPredict,testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
??plot.enet
install.packages("plot.enet")
install.packages("elasticnet")
?plot.enet
install.packages("enet")
library(elasticnet)
?plot.enet
modFi3<-train(CompressiveStrength~.,method="lda",data=training)
modFi3<-train(CompressiveStrength~.,method="lasso",data=training)
plot.enet(modFi3,training$CompressiveStrength)
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
modFit3<-train(CompressiveStrength~.,method="lasso",data=training)
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
legend(attributes(model$finalModel))
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE,legend=attributes(model$finalModel))
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE,legend=attributes(modFit3$finalModel))
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
legend(attributes(modFit3$finalModel))
par(mfrow=c(2,2))
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
par(mfrow=c(1,1))
plot.enet(modFit3$finalModel,xvar="penalty",use.color=TRUE)
attributes(modFit3$finalModel)
?plot.enet
library(lubridate)  # For year() function below
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
??bats
install.packages("forecast")
library(forecast)
?bats
head(testing)
?ts
?bats
bats(testing$visitsTumblr)
forecast<-bats(testing$visitsTumblr)
str(forecast)
forecast2<-predict(forecast,testing)
tstest = ts(testing$visitsTumblr)
forecast<-bats(tstrain)
forecast2<-predict(forecast,tstest)
forecast2<-forecast(forecast,tstest)
?forecast
forecast2<-forecast(forecast)
model<-bats(tstrain)
forecast<-forecast(model)
str(forecast)
plot(forecast);
lines(tstest,col='red')
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
model<-bats(tstrain)
forecast<-forecast(model)
plot(forecast);
lines(tstest,col='red')
head(testing)
testing
?forecast
forecast<-forecast(model,600)
plot(forecast);
training
lines(tstest,col="red")
lines(rbind(tstrain,tstest,col="red")
lines(rbind(tstrain,tstest),col="red")
lines(rbind(tstrain,tstest),col="red")
plot(forecast);
lines(rbind(tstrain,tstest),col="red")
nrow(testing)
nrow(training)
nrow(testing)
forecast<-forecast(model,235)
plot(forecast);
lines(rbind(tstrain,tstest),col="red")
lines(tstest,col="red")
str(tstrain)
ts=ts(dat$visitsTumblr)
plot(forecast);
lines(ts,col="red")
str(forecast)
?forecast
forecast$level
forecast$lower
forecast$upper
data.frame(forecast$lower[,2],forecast$upper[,2],tstest,inside=(tstest>=forecast$lower[,2] & tstest<=forecast$uppder[,2]))
data.frame(forecast$lower[,2],forecast$upper[,2],tstest)
data.frame(forecast$lower[,2],forecast$upper[,2],tstest,inside=(tstest>=forecast$lower[,2] & tstest<=forecast$uppder[,2]))
data.frame(forecast$lower[,2],forecast$upper[,2],tstest,inside=(tstest>=forecast$lower[,2] & tstest<=forecast$upper[,2]))
prediction<-data.frame(forecast$lower[,2],forecast$upper[,2],tstest,inside=(tstest>=forecast$lower[,2] & tstest<=forecast$upper[,2]))
nrow(prediction)
sum(prediction$inside)/nrow(prediction)
forecast<-forecast(model,235)
plot(forecast);
lines(ts,col="red")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
?svm
set.seed(325)
fitModel5<-svm(CompressiveStrength~.,data=training)
predictModel5<-predict(fitModel5,newdata=testing)
summary(RMSE)
summary(predictModel5)
predictModel5
sqrt(sum((predictModel5=testing$CompressiveStrength)^2))
RMSE=sqrt(sum((predictModel5=testing$CompressiveStrength)^2))
RMSE
accuracy(forecast,tstest)
RMSE=sqrt(sum((predictModel5=testing$CompressiveStrength)^2))/lenght(testing)
RMSE
lenght(testing)
length(testing)
RMSE=sqrt(sum((predictModel5=testing$CompressiveStrength)^2))/length(testing)
RMSE
RMSE=sqrt(sum((predictModel5-testing$CompressiveStrength)^2))
RMSE
predictModel5
testing$CompressiveStrength
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fitModel5<-svm(CompressiveStrength~.,data=training)
predictModel5<-predict(fitModel5,newdata=testing)
RMSE=sqrt(sum((predictModel5-testing$CompressiveStrength)^2))
RMSE
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
ts=ts(dat$visitsTumblr)
model<-bats(tstrain)
forecast<-forecast(model,235)
plot(forecast); lines(ts,col="red")
accuracy(forecast,tstest)
RMSE=sqrt(sum((predictModel5-testing$CompressiveStrength)^2))/nrow(testing)
RMSE
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fitModel5<-svm(CompressiveStrength~.,data=training)
predictModel5<-predict(fitModel5,newdata=testing)
RMSE=sqrt(sum((predictModel5-testing$CompressiveStrength)^2))/nrow(testing)
RMSE
nrow(testing)
length(predictModel5)
RMSE=sqrt(sum((predictModel5-testing$CompressiveStrength)^2))/length(predictModel5)
RMSE
accuracy(predictModel5,testing$CompressiveStrength)
RMSE<-accuracy(predictModel5,testing$CompressiveStrength)[,2]
RMSE
RMSE<-sqrt(sum((predictModel5 - testing$CompressiveStrength)^2))
RMSE
RMSE<-mean(sum((predictModel5 - testing$CompressiveStrength)^2))
RMSE
RMSE<-sqrt(mean((predictModel5 - testing$CompressiveStrength)^2))
RMSE
RMSE<-sqrt(sum((predictModel5 - testing$CompressiveStrength)^2)/nrow(predictModel5))
RMSE
nrow(predictModel5)
nrow(testing)
RMSE<-sqrt(sum((predictModel5 - testing$CompressiveStrength)^2)/nrow(testing))
RMSE
accuracy(forecast,tstest)
forecast
str(forecast)
accuracy(forecast$fitted.values,tstest)
accuracy(forecast$mean,tstest)
?accuracy
tstest
accuracy(forecast,tstest)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
ts=ts(dat$visitsTumblr)
model<-bats(tstrain)
forecast<-forecast(model,235)
accuracy(forecast,tstest)
nrow(tstrain)
nrow(tstest)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(testing$visitsTumblr)
nrow(tstrain)
nrow(tstest)
nrow(training)
nrow(testing)
tstrainW<-window(tstrain,start=1,end=365)
tstestW<-window(tstest,start=366,end=(365+235))
tstestW<-window(tstest,start=366,end=500)
tstestW<-window(tstest,start=365,end=500)
tstestW<-window(tstest,start=365,end=(500-0.01))
tstrainW<-window(tstrain,start=1,end=1)
tstestW<-window(tstest,start=2,end=(2-0.01))
tstrainW<-window(tstrain,start=1,end=1)
tstestW<-window(tstest,start=2,end=(2-0.01))
tstestW<-window(tstest,start=1,end=(2-0.01))
?window
tstrainW<-window(tstrain,start=1,end=1)
tstestW<-window(tstest,start=1,end=2)
forecast<-forecast(model,1)
forecast<-forecast(model,1)
accuracy(forecast,tstest)
forecast<-forecast(model,1)
accuracy(forecast,tstest)
forecast<-forecast(model,2)
accuracy(forecast,tstest)
plot(forecast); lines(ts,col="red")
training
testing
tstrainW<-window(tstrain,start=1,end=365)
tstestW<-window(tstest,start=366,end=600)
tstestW<-window(tstest,start=1,end=235)
forecast<-forecast(model,235)
accuracy(forecast,tstest)
forecast
accuracy(forecast[366:600,],tstest)
tstest
forecast[366:600,]
forecast[366:600,]
forecast$fitted
tsdat=ts(testing$visitsTumblr)
head(tsdat)
tstrainW<-window(tsdat,start=1,end=365)
tstestW<-window(tsdat,start=366,end=600)
tstrainW<-window(tsdat,start=1,end=365)
tsdat
tsdat=ts(dat$visitsTumblr)
tstrainW<-window(tsdat,start=1,end=365)
tstestW<-window(tsdat,start=366,end=600)
model<-bats(tstrainW)
forecast<-forecast(model,235)
plot(forecast); lines(tstestW,col="red")
accuracy(forecast,tstestW)
prediction<-data.frame(forecast$lower[,2],forecast$upper[,2],tstest,inside=(tstest>=forecast$lower[,2] & tstest<=forecast$upper[,2]))
sum(prediction$inside)/nrow(prediction)
tstrainW
tstestW
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
library(caret)
set.seed(33833)
modFit1<-train(y~.,method="rf",data=vowel.train)
modFit2<-train(y~.,method="gbm",data=vowel.train)
predict1<-predict(modFit1,newdata=vowel.test)
predict2<-predict(modFit2,newdata=vowel.test)
confusionMatrix(predict1,vowel.test$y)
confusionMatrix(predict2,vowel.test$y)
sum(predictData$predict1==predictData$predict2)/nrow(predictData)
library(caret)
set.seed(33833)
modFit1<-train(y~.,method="rf",data=vowel.train)
set.seed(33833)
modFit2<-train(y~.,method="gbm",data=vowel.train)
predict1<-predict(modFit1,newdata=vowel.test)
predict2<-predict(modFit2,newdata=vowel.test)
confusionMatrix(predict1,vowel.test$y)
confusionMatrix(predict2,vowel.test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
library(caret)
modFit1<-train(y~.,method="rf",data=vowel.train)
modFit2<-train(y~.,method="gbm",data=vowel.train)
predict1<-predict(modFit1,newdata=vowel.test)
predict2<-predict(modFit2,newdata=vowel.test)
confusionMatrix(predict1,vowel.test$y)
confusionMatrix(predict2,vowel.test$y)
base<-read.csv("activity.csv")
setwd("~/Dropbox/Rfiles/ReproducibleResearch/RepData_PeerAssessment1")
base<-read.csv("activity.csv")
head(base)
head(base,100)
head(base,500)
head(base,2000)
head(base,2)
base_day<-ddply(base,~date,summarize,steps_day=mean(steps))
library(ddply)
library(plyr)
base_day<-ddply(base,~date,summarize,steps_day=mean(steps))
head(base_day)
hist(base_day$steps_day)
base_day<-ddply(base,~date,summarize,steps_day=sum(steps))
hist(base_day$steps_day)
mean(base_day$steps_day),median(base_day$steps_day)
cbind(mean(base_day$steps_day),median(base_day$steps_day))
?mean
cbind(mean(base_day$steps_day,na.rm=TRUE),median(base_day$steps_day))
base_day<-ddply(base,~date,summarize,steps_day=sum(steps))
hist(base_day$steps_day)
base_day
base_day<-ddply(base,~date,summarize,steps_day=sum(steps))
base_day
base
head(base,2)
head(base,200)
base_day<-ddply(base,~date,summarize,steps_day=sum(steps))
hist(base_day$steps_day)
cbind(mean(base_day$steps_day,na.rm=TRUE),median(base_day$steps_day))
cbind(mean(base_day$steps_day,na.rm=TRUE),median(base_day$steps_day,na.rm=TRUE)))
?median
cbind(mean(base_day$steps_day,na.rm=TRUE),median(base_day$steps_day,na.rm=TRUE))
mean(base_day$steps_day,na.rm=TRUE)
median(base_day$steps_day,na.rm=TRUE))
mean(base_day$steps_day,na.rm=TRUE)
median(base_day$steps_day,na.rm=TRUE)
?merge
head(base,2)
merge(base,base_day,by.date=by.date)
base_day<-ddply(base,~date,summarize,steps_day=sum(steps,na.rm=TRUE))
hist(base_day$steps_day)
base2<-merge(base,base_day,by.date=by.date)
head(base2)
head(base2,200)
head(base2,1000)
nrows(base)
nrows(base2)
nrow(base)
nrow(base2)
head(base2,10)
plot(interval,steps)
plot(base2$interval,base2$steps)
plot(base2$interval,base2$steps, type="l")
base_interval<-ddply(base,~interval,summarize,steps_interval=sum(steps,na.rm=TRUE))
head(base_interval)
plot(base_interval$interval,base_interval$steps_interval, type="l")
base_interval[steps_interval=max(base_interval$steps_interval),]
max(base_interval$steps_interval)
max<-max(base_interval$steps_interval)
base_interval[steps_interval==max,]
base_interval[base_interval$steps_interval==max,]
base_interval[base_interval$steps_interval==max,]$interval
max_inteval<-base_interval[base_interval$steps_interval==max,]$interval
max_interval
max_interval<-base_interval[base_interval$steps_interval==max,]$interval
max_interval
is_na<-sum(is.na(base$steps))
is_na
is_na<-sum(is.na(base$steps))
is_na
base_filled<-base
base_filled$steps2<-if(is.na(steps)==TRUE) {base_interval[base_interval$interval=base_filled$intevalr,]}
base_filled$steps2<-(if(is.na(steps)==TRUE) {base_interval[base_interval$interval=base_filled$intevalr,]})
base_filled$steps2<-(if(is.na(steps)==TRUE) {base_interval[base_interval$interval==base_filled$intevalr,]})
head(base_filled)
base_filled$steps2<-(if(is.na(base_filled$steps)==TRUE) {base_interval[base_interval$interval==base_filled$intevalr,]})
library(sqldf)
sqldf("select top 10 * from base_filled")
library(tcltk)
sqldf("select top 10 * from base_filled")
sqldf("select * from iris limit 5")
str(iris)
sqldf("select * from base_filled limit 5")
base_filled<-merge(base,base_interval,x.interval=y.interval)
head(base_filled)
head(base_filled,200)
base_filled$steps2<-if(is.na(base_filled$steps)==TRUE){base_filled$steps_interval}
if(is.na(base_filled$steps)==TRUE)
{base_filled$steps2<-base_filled$steps_interval}
else
{base_filled$steps2<-base_filled$steps}
head(base_filled,200)
head(base_filled,10)
base_filled$steps2<-ifelse(is.na(base_filled$steps)==TRUE, base_filled$steps_interval,base_filled$steps2<-base_filled$steps)
head(base_filled,10)
base_interval
head(base_filled,10)
head(base_filled,1000)
max_interval
base_filled<-merge(base,base_interval,x.interval=y.interval)
base_filled$steps<-ifelse(is.na(base_filled$steps)==TRUE, base_filled$steps_interval,base_filled$steps)
head(base_filled,1000)
head(base_filled,10)
hist(base_filled$steps)
base_day_filled<-ddply(base_filled,~date,summarize,steps_day=sum(steps,na.rm=TRUE))
hist(base_day_filled$steps_day)
mean(base_day_filled$steps_day,na.rm=TRUE)
median(base_day_filled$steps_day,na.rm=TRUE)
head(base_day_filled)
weekdays(base_filled$date)
str(base_filled)
weekdays(as.date(base_filled$date))
weekdays(as.Date(base_filled$date))
Sys.setenv(LANG="EN")
weekdays(as.Date(base_filled$date))
Sys.setenv(LANG="EN")
head(weekdays(as.Date(base_filled$date)))
?weekdays?
?weekdays
Sys.setenv(LANG = "en_US.UTF-8")
head(weekdays(as.Date(base_filled$date)))
Sys.getlocale()
Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
Sys.getlocale()
head(weekdays(as.Date(base_filled$date)))
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
defaults write org.R-project.R force.LANG en_US.UTF-8
force.LANG en_US.UTF-8
head(weekdays(as.Date(base_filled$date)))
Sys.setenv(LANG="EN")
head(weekdays(as.Date(base_filled$date)))
Sys.setlocale("LC_TIME","English United States")
Sys.setlocale("LC_TIME", "en_US")
head(weekdays(as.Date(base_filled$date)))
base_filled$week_part<-ifelse(weekdays(as.Date(base_filled$date))=="Saturday","weekend","weekday")
base_filled$week_part<-ifelse(weekdays(as.Date(base_filled$date))=="Saturday" || weekdays(as.Date(base_filled$date))=="Sunday","weekend","weekday")
head(base_filled)
base_filled$weekday<-weekdays(as.Date(base_filled$date))
head(base_filled)
base_filled$week_part<-ifelse(weekdays(as.Date(base_filled$date))=="Saturday","weekend","weekday")
head(base_filled)
base_filled$week_part<-ifelse(weekdays(as.Date(base_filled$date))=="Saturday" || weekdays(as.Date(base_filled$date))=="Sunday","weekend","weekday")
head(base_filled)
base_filled$week_part<-ifelse((weekdays(as.Date(base_filled$date))=="Saturday" || weekdays(as.Date(base_filled$date))=="Sunday"),"weekend","weekday")
head(base_filled)
base_filled$week_part<-ifelse((weekdays(as.Date(base_filled$date))=="Saturday" | weekdays(as.Date(base_filled$date))=="Sunday"),"weekend","weekday")
head(base_filled)
as.factor(base_filled$week_part)
base_filled$week_part<-as.factor(base_filled$week_part)
str(base_filled)
base_day_filled_week<-ddply(base_filled,~date+week_part,summarize,steps_day=sum(steps,na.rm=TRUE))
head(base_day_filled_week)
base_day_filled_week<-ddply(base_filled,~interval+week_part,summarize,steps_day=sum(steps,na.rm=TRUE))
head(base_day_filled_week)
plot(base_day_filled_week$interval,steps_day)
plot(base_day_filled_week$interval,base_day_filled_week$steps_day)
plot(base_day_filled_week$interval,base_day_filled_week$steps_day,type="l")
?plot
plot(base_day_filled_week$interval,base_day_filled_week$steps_day,type="l",par=week_part)
plot(base_day_filled_week$interval,base_day_filled_week$steps_day,type="l",par=base_day_filled_week$week_part)
?par
plot(base_day_filled_week$interval,base_day_filled_week$steps_day,type="l",legend=base_day_filled_week$week_part)
require(ggplot2)
ggplot(base_day_filled_week, aes(x=interval, y=steps)) + #define the data that the plot will use, and which variables go where
geom_line() + #plot it with points
facet_wrap(~week_part)
head(base_day_filled_week)
ggplot(base_day_filled_week, aes(x=interval, y=steps_day)) + #define the data that the plot will use, and which variables go where
geom_line() + #plot it with points
facet_wrap(~week_part)
ggplot(base_day_filled_week, aes(x=interval, y=steps_day)) + #define the data that the plot will use, and which variables go where
geom_line() + #plot it with points
facet_wrap(~week_part,nrow=2)
base<-read.csv("activity.csv")
head(base,2)
base<-read.csv("activity.csv")
base$date<-as.date(base$date)
base$date<-as.Date(base$date)
?hist
The number of intervals with NA values are:
sum(base$steps)
sum(base$steps,rm.na=TRUE)
sum(base$steps,rm.na=FALSE)
sum(base$steps,na.rm=FALSE)
sum(base$steps,na.rm=TRUE)
sum(base_day$steps_day,na.rm=TRUE)
sum(base_interval$steps_interval,na.rm=TRUE)
sum(base_filled$steps,na.rm=TRUE)
nrow(base_filled)
nrow(base)
nrow(base_filled)
head(base_filled)
The plot below show the average number of steps taken per 5-minute interval:
